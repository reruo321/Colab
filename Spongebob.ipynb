{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spongebob",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPvmXDSFNAY1PPPqyQuk3E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_FPq8qKkF1S"
      },
      "source": [
        "## Labelling Images\n",
        "\n",
        "We will use some images for new label, using \"LabelImg\" tool.\n",
        "\n",
        "https://github.com/tzutalin/labelImg#usage\n",
        "\n",
        "Since Google Colab does not support GUI applications, we should use this tool in our environment.\n",
        "\n",
        "> pip install labelimg\n",
        "\n",
        "> labelimg\n",
        "\n",
        "Let's save the files as XML format.\n",
        "\n",
        "Convert XML files into CSV, and into TFRecord files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtyRMeqhka8I"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkNYZFVtRIrc"
      },
      "source": [
        "Example: https://keras.io/examples/keras_recipes/tfrecord/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SErYb4DM5mp"
      },
      "source": [
        "Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M5_97BccbIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bd923a-19ec-42fc-ff28-86adb2796f93"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "!pip install -q -U tf-hub-nightly\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from functools import partial\n",
        "import os\n",
        "import zipfile\n",
        " \n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███                             | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 24.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 51kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 61kB 16.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 71kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 81kB 13.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 92kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 102kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 12.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G-4KFYO5OkMS",
        "outputId": "76591e42-a908-4e31-ea66-d06e54415279"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G14ajNZZlbF"
      },
      "source": [
        "Load the TFRecord for adding a new label, from my Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6ypX73Zkzz"
      },
      "source": [
        "#train_id = \"https://drive.google.com/file/d/1BcgncfyipV8V_eTG4UmPSAosNfpKEndf/view?usp=sharing\"\n",
        "#valid_id = \"https://drive.google.com/file/d/1kseKkBh4Blw6uLqqpSFkuIlQ06FoVt6V/view?usp=sharing\"\n",
        "#test_id = \"https://drive.google.com/file/d/1s-41CVh9U80I7EYqRoMABTykX2ZcHcHw/view?usp=sharing\"\n",
        " \n",
        "os.makedirs('/tfrecord')\n",
        "os.makedirs('/tfrecord/train')\n",
        "os.makedirs('/tfrecord/valid')\n",
        "os.makedirs('/tfrecord/test')\n",
        " \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        " \n",
        "tfr_train = drive.CreateFile({'id':\"1BcgncfyipV8V_eTG4UmPSAosNfpKEndf\"})\n",
        "tfr_train.GetContentFile('/tfrecord/train/train.tfrecord')\n",
        "\n",
        "tfr_valid = drive.CreateFile({'id':\"1kseKkBh4Blw6uLqqpSFkuIlQ06FoVt6V\"})\n",
        "tfr_valid.GetContentFile('/tfrecord/valid/valid.tfrecord')\n",
        "\n",
        "tfr_test = drive.CreateFile({'id':\"1s-41CVh9U80I7EYqRoMABTykX2ZcHcHw\"})\n",
        "tfr_test.GetContentFile('/tfrecord/test/test.tfrecord')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfwSjzVugked",
        "outputId": "bb7bfdb3-1fc3-4388-a4e4-3db2fea263a9"
      },
      "source": [
        "TRAINING_FILENAMES = tf.io.gfile.glob(\"/tfrecord/train/*.tfrecord\")\n",
        "VALID_FILENAMES = tf.io.gfile.glob(\"/tfrecord/test/*.tfrecord\")\n",
        " \n",
        "TEST_FILENAMES = tf.io.gfile.glob(\"/tfrecord/test/*.tfrecord\")\n",
        "print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n",
        "print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n",
        "print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train TFRecord Files: 1\n",
            "Validation TFRecord Files: 1\n",
            "Test TFRecord Files: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us3bDgbhrTmL"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = [300, 300]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eidSAHbnqs5q"
      },
      "source": [
        "Decode image data to tensor format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhbw5Ftzqn55"
      },
      "source": [
        " \n",
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE, method = tf.image.ResizeMethod.BILINEAR)    \n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP-BS6YTq8BU"
      },
      "source": [
        "Read TFRecord file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwujFBedq7cT"
      },
      "source": [
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = (\n",
        "        {\n",
        "            \"encoded\": tf.io.FixedLenFeature([], tf.string), #image/encoded\n",
        "            \"source_id\": tf.io.FixedLenFeature([], tf.string), #image/source_id\n",
        "        }\n",
        "        if labeled\n",
        "        else {\"encoded\": tf.io.FixedLenFeature([], tf.string),}\n",
        "    )\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example[\"encoded\"])\n",
        "    if labeled:\n",
        "        label = tf.cast(example[\"source_id\"], tf.string)\n",
        "        return image, label\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oysFvOLRre2E"
      },
      "source": [
        " \n",
        "def load_dataset(filenames, labeled=True):\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(\n",
        "        filenames\n",
        "    )  # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(\n",
        "        ignore_order\n",
        "    )  # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(\n",
        "        partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UYfYI1orhX-"
      },
      "source": [
        "def get_dataset(filenames, labeled=True):\n",
        "    dataset = load_dataset(filenames, labeled=labeled)\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Y3FKJE4Sri-f",
        "outputId": "e5241ff8-382a-4f3c-afb4-e4ac1b426c3b"
      },
      "source": [
        "train_dataset = get_dataset(TRAINING_FILENAMES)\n",
        "valid_dataset = get_dataset(VALID_FILENAMES)\n",
        "test_dataset = get_dataset(TEST_FILENAMES, labeled=False)\n",
        " \n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        " \n",
        " \n",
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for n in range(5):\n",
        "        ax = plt.subplot(5, 5, n + 1)\n",
        "        plt.imshow(image_batch[n] / 255.0)\n",
        "        if label_batch[n]:\n",
        "            plt.title(\"spongebob\")\n",
        "        else:\n",
        "            plt.title(\"???\")\n",
        "        plt.axis(\"off\")\n",
        " \n",
        " \n",
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Feature: encoded (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c89b83e405c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Feature: encoded (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B_a2dg3rkew"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"melanoma_model.h5\", save_best_only=True\n",
        ")\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r25Tu3J8rnPo"
      },
      "source": [
        "\n",
        "def make_model():\n",
        "    base_model = tf.keras.applications.Xception(\n",
        "        input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n",
        "    x = tf.keras.applications.xception.preprocess_input(inputs)\n",
        "    x = base_model(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.7)(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=tf.keras.metrics.AUC(name=\"auc\"),\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_TnW5DqrobK"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = make_model()\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=2,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP4wkZqerpiQ"
      },
      "source": [
        "\n",
        "def show_batch_predictions(image_batch):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for n in range(25):\n",
        "        ax = plt.subplot(5, 5, n + 1)\n",
        "        plt.imshow(image_batch[n] / 255.0)\n",
        "        img_array = tf.expand_dims(image_batch[n], axis=0)\n",
        "        plt.title(model.predict(img_array)[0])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "image_batch = next(iter(test_dataset))\n",
        "\n",
        "show_batch_predictions(image_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbPAmRJRNkeR"
      },
      "source": [
        "\n",
        "\n",
        "Import pre-trained object detection model (SSD Openimages v4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGegaZzbM5JW"
      },
      "source": [
        "classifier_url =\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxr4CRsPIPZ"
      },
      "source": [
        "wget classifier_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bopnAMbzxNk5"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGurOL0YuxiF"
      },
      "source": [
        "Configure the .config file in the model\n",
        "\n",
        "https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXWxJOnhu45w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}